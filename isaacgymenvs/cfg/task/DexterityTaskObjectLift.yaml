# See schema in factory_schema_config_task.py for descriptions of common parameters.

defaults:
    - _self_
    # - /factory_schema_config_task

name: DexterityTaskObjectLift
physics_engine: ${..physics_engine}
full_experiment_name: ${..experiment}
test: ${..test}

enableCameraSensors: True  # Set to true to test visual observations

calibrate: False

sim:
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
    up_axis: "z"
    dt: 0.016666667  # required, but overridden in DexterityBase.yaml
    gravity: [0.0, 0.0, -9.81]  # required, but overridden in base DexterityBase.yaml
    disable_gravity: False

env:
    numEnvs: ${resolve_default:16384,${...num_envs}}
    numObservations: 0  # overwritten depending on observations
    numActions: 0  # overwritten depending on robot configuration

    # Observations specified here will be available to the agent in the obs_dict under the key 'obs' for regular proprioceptive observations such as poses, under the key 'image' for observations coming from image sensors, such as RGB or depth images.
    observations: ['ctrl_target_ik_body_pos', 'ctrl_target_ik_body_quat', 'ctrl_target_residual_actuated_dof_pos', 'ik_body_pos', 'ik_body_quat', 'fingertips_pos', 'object_pos', 'object_linvel', 'object_bounding_box_as_points', 'frontview']
    #observations: ['ctrl_target_ik_body_pos', 'ctrl_target_ik_body_quat', 'ctrl_target_residual_actuated_dof_pos', 'ik_body_pos', 'ik_body_quat', 'synthetic_pointcloud' ]
    #observations: ['ctrl_target_ik_body_pos', 'ctrl_target_ik_body_quat', 'ctrl_target_residual_actuated_dof_pos', 'ik_body_pos', 'ik_body_quat', 'frontview']
    teacher_observations: ['ctrl_target_ik_body_pos', 'ctrl_target_ik_body_quat', 'ctrl_target_residual_actuated_dof_pos', 'ik_body_pos', 'ik_body_quat', 'fingertips_pos', 'object_pos', 'object_linvel', 'object_bounding_box_as_points' ]

    # If obs_as_dict is True, the observation is returned as a dictionary instead of a single vector.
    obs_as_dict: False

    controlFrequencyInv: 8


randomize:
    observations:
        pointcloud:
            noise_prob: 0.0
            noise_std: 0.001

    # ik_body start pose.
    ik_body_pos_initial:  # initial position of ik_body
        default: [0.6, 0., 0.5]
        real_robot: [0.28, 0.58, 0.5]
    ik_body_euler_initial:  # initial rotation of ik_body
        default: [0., 0., 0.]
        real_robot: [0.0, 0.0, 1.571]
    ik_body_euler_noise: [0.0, 0.0, 0.0]  # noise on ik_body rotation
    ik_body_pos_noise: [0.0, 0.0, 0.0]  # noise on ik_body position

    move_to_pregrasp_pose: False

    num_ik_body_initial_move_steps: 2  # number of steps to reach initial pose

    # object drop position.
    object_pos_drop:  # position from which object is dropped
        default: [0.6, 0.0, 0.5]
        real_robot: [0.28, 0.58, 0.5]
    object_pos_drop_noise: [0.05, 0.05, 0.0]

    num_object_drop_steps: 100  # number of steps to drop objects

    # workspace extent, outside which objects will be dropped again.
    workspace_extent_xy:
        default: [[-0.2, -0.2], [0.2, 0.2]]
        real_robot: [[-0.075, -0.075], [0.075, 0.075]]

rl:
    reward:
        action_penalty: 0.001  # scale on action penalty
        #manipulator_contact_penalty: 1.0
        arm_contact_penalty: 1.0
        fingertips_closeness: 0.1
        liftoff_pointcloud_clearance: 25.0
        task_progression: 1.0
        success_bonus: 50.0
        visibility_ratio: 20.0


    liftoff_height: 0.02  # height added to the object's position in meters to count as lifted. Makes dense feedback easier
    target_pos: [0.28, 0.58, 0.25]
    target_threshold: 0.05
    max_episode_length: 75
